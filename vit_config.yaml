model_architecture:
    image_size: [32, 32, 3]
    patch_size: 2
    patch_embedding_dim: 512
    num_attention_heads: 8
    num_transformer_encoder: 6
    mlp_units: 512
    dropout_rate: 0.1
    model_name: cifar_viT


training_settings:
    epochs: 120
    batch_size: 8
    learning_rate: 0.0002 
    save_plots: True
    show_plots: False
    
save_paths:
    model_save_path: model_weights
    plot_save_path: runs
